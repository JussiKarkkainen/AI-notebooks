{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e72SSe3aJzfT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params(vocab_size, num_hiddens):\n",
        "    # Input gate params\n",
        "    W_hi = torch.normal(0, 0.01, (vocab_size, num_hiddens), requires_grad=True)\n",
        "    W_xi = torch.normal(0, 0.01, (num_hiddens, num_hiddens), rewuires_grad=True)\n",
        "    b_i = torch.zeros(num_hiddens, requires_grad=True)\n",
        "    # Forget gate params\n",
        "    W_hf = torch.normal(0, 0.01, (vocab_size, num_hiddens), requires_grad=True)\n",
        "    W_xf = torch.normal(0, 0.01, (num_hiddens, num_hiddens), requires_grad=True)\n",
        "    b_f = torch.zeros(num_hiddens, requires_grad=True)\n",
        "    # Output gate params\n",
        "    W_ho = torch.normal(0, 0.01, (vocab_size, num_hiddens), requires_grad=True)\n",
        "    W_xo = torch.normal(0, 0.01, (num_hiddens, num_hiddens), requires_grad=True)\n",
        "    b_o = torch.zeros(num_hiddens, requires_grad=True)\n",
        "    # Memory cell params\n",
        "    W_hc = torch.normal(0, 0.01, (vocab_size, num_hiddens), requires_grad=True)\n",
        "    W_xc = torch.normal(0, 0.01, (num_hiddens, num_hiddens), requires_grad=True)\n",
        "    b_c = torch.zeros(num_hiddens, requires_grad=True)\n",
        "    # Output later params\n",
        "    W_hq = torch.normal(0, 0.01, (num_hiddens, num_outputs), requires_grad=True)\n",
        "    b_q = torch.zeros(num_outputs, requires_grad=True)\n",
        "    params = [W_hi, W_xi, bi, W_hf, W_xf, b_f, W_ho, W_xo, b_o, W_hc, W_xc, b_c]\n",
        "    return params"
      ],
      "metadata": {
        "id": "wqIeukPHJ3-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_state(batch_size, num_hiddens):\n",
        "    return (torch.zeros(batch_size, num_hiddens), torch.zeros(batch_size, num_hiddens))"
      ],
      "metadata": {
        "id": "9x9TYiZKNpXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm(inputs, state, params):\n",
        "    W_hi, W_xi, bi, W_hf, W_xf, b_f, W_ho, W_xo, b_o, W_hc, W_xc, b_c = params\n",
        "    H, C = init_state()\n",
        "    outputs = []\n",
        "    for x in inputs:\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=nn+lstm#torch.nn.LSTM\n",
        "        I = torch.sigmoid((W_xi @ x) + (W_hi @ H) + b_i)\n",
        "        F = torch.sigmoid((W_xf @ x) + (W_hf @ H) + b_f)\n",
        "        O = torch.sigmoid((W_xo @ x) + (W_ho @ H) + b_o)\n",
        "        G = torch.tanh((W_xc @ x) + (W_hc @ H) + b_c)\n",
        "        C = F * C + I * G\n",
        "        H = O * torch.tanh(C)\n",
        "        Y = (W_hq @ H) + b_q\n",
        "        outputs.append(Y)\n",
        "    return torch.cat(outputs, dim=0), (H, C)"
      ],
      "metadata": {
        "id": "I__StWZMK1I1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}