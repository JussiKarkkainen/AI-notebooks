{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNfromscratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBZCHF7jAbbU"
      },
      "source": [
        "from google.colab import files\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qllp-bvg85GT"
      },
      "source": [
        "files = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pvqMWDk9rnQ"
      },
      "source": [
        "def get_lines():\n",
        "  with open('ptb.train.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  return lines\n",
        "\n",
        "lines = get_lines()\n",
        "print(lines[0:1000])\n",
        "print(len(lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QwQcN8d-QE3"
      },
      "source": [
        "def tokenize(lines, token):\n",
        "  if token == 'word':\n",
        "    Tokens = [line.split() for line in lines]\n",
        "  elif token == 'char':\n",
        "    Tokens = [list(line) for line in lines]\n",
        "\n",
        "  return Tokens\n",
        "\n",
        "Tokens = tokenize(lines, token='char')\n",
        "print(Tokens[0:100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyayDlmfD7mh"
      },
      "source": [
        "def flatten(Tokens):\n",
        "  return [item for i in Tokens for item in i]\n",
        "\n",
        "tokens = flatten(Tokens)\n",
        "print(tokens[0:100])\n",
        "print(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwfOsaBdGWxj"
      },
      "source": [
        "def unique_tokens(tokens):\n",
        "  unique_tok = []\n",
        "  for i in tokens:\n",
        "    if i not in unique_tok:\n",
        "      unique_tok.append(i)\n",
        "\n",
        "  return unique_tok\n",
        "\n",
        "uniq_tokens = unique_tokens(tokens)\n",
        "print(uniq_tokens[0:100])\n",
        "print(len(uniq_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcb0m3Qr212m"
      },
      "source": [
        "character_dict = {}\n",
        "for e, char in enumerate(uniq_tokens):\n",
        "  character_dict[char] = e\n",
        "print(character_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps5Y_i9t3aqC"
      },
      "source": [
        "ptb_numerical = [character_dict[char] for char in tokens]\n",
        "print(len(ptb_numerical))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDGLw0gV5AKA"
      },
      "source": [
        "print(\"\".join([uniq_tokens[idx] for idx in ptb_numerical[:100]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba4eWHZAULIx"
      },
      "source": [
        "def one_hot_data(numerical_list, vocab_size=50):\n",
        "    result = torch.zeros((len(numerical_list), vocab_size))\n",
        "    for i, idx in enumerate(numerical_list):\n",
        "        result[i, idx] = 1.0\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92r8gBg4gSv"
      },
      "source": [
        "print(one_hot_data(ptb_numerical[:2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2aKiYe2Jlc"
      },
      "source": [
        "def textify(embedding):\n",
        "    result = \"\"\n",
        "    indices = torch.argmax(embedding, axis=1)\n",
        "    for idx in indices:\n",
        "        result += uniq_tokens[int(idx)]\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkukM_YXnI58"
      },
      "source": [
        "seq_length = 64\n",
        "num_samples = (len(ptb_numerical) - 1) // seq_length\n",
        "dataset = one_hot_data(ptb_numerical[:num_samples * seq_length]).reshape(num_samples, seq_length, len(uniq_tokens))\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf3WA8rjqUp1"
      },
      "source": [
        "batch_size = 32\n",
        "num_batches = len(dataset) // batch_size\n",
        "train_iter = dataset[:num_batches * batch_size].reshape((batch_size, num_batches, seq_length, len(uniq_tokens)))\n",
        "train_iter = train_iter.swapaxes(0, 1)\n",
        "train_iter = train_iter.swapaxes(1, 2)\n",
        "train_iter.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knAFHA4dx-G1"
      },
      "source": [
        "labels = one_hot_data(ptb_numerical[1:num_samples * seq_length + 1]).reshape(batch_size, num_batches, seq_length, len(uniq_tokens))\n",
        "labels = labels.swapaxes(0, 1)\n",
        "labels = labels.swapaxes(1, 2)\n",
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saSpRvG4BZnT"
      },
      "source": [
        "print(textify(train_iter[10, :, 3]))\n",
        "print(textify(labels[10, :, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY_KqOPcUQfF"
      },
      "source": [
        "class RNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.W_xh = torch.normal(0, 0.01, (50, 256), requires_grad=True)\n",
        "    self.W_hh = torch.normal(0, 0.01, (256, 256), requires_grad=True)\n",
        "    self.b_h = torch.zeros(1, 256, requires_grad=True)\n",
        "\n",
        "    self.W_hq = torch.normal(0, 0.01, (256, 50), requires_grad=True)\n",
        "    self.b_q = torch.zeros(1, 50, requires_grad=True)\n",
        "    self.params = [self.W_xh, self.W_hh, self.b_h, self.W_hq, self.b_q]\n",
        "    for param in self.params:\n",
        "      param.requires_grad_(True)\n",
        "  \n",
        "  def net(self, input, state):\n",
        "    hidden_act = state\n",
        "    outputs = []\n",
        "    for X in input:\n",
        "      hidden = torch.matmul(X, self.W_xh) + torch.matmul(hidden_act, self.W_hh) + self.b_h\n",
        "      hidden_act = torch.nn.Tanh(hidden)\n",
        "      outputs.append(torch.matmul(hidden_act, self.W_hq) + self.b_q)\n",
        "\n",
        "      return output, hidden_act\n",
        "\n",
        "  def init_rnn_hidden(self):\n",
        "    return torch.zeros((1, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-o4dni6TVsB"
      },
      "source": [
        "\n",
        "W_xh = torch.normal(0, 0.01, (50, 256), requires_grad=True)\n",
        "W_hh = torch.normal(0, 0.01, (256, 256), requires_grad=True)\n",
        "b_h = torch.zeros(1, 256, requires_grad=True)\n",
        "\n",
        "W_hq = torch.normal(0, 0.01, (256, 50), requires_grad=True)\n",
        "b_q = torch.zeros(1, 50, requires_grad=True)\n",
        "params = [W_xh, W_hh, b_h, W_hq, b_q]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99gpLDZTx8X"
      },
      "source": [
        "def net(input, state):\n",
        "  W_xh, W_hh, b_h, W_hq, b_q = params\n",
        "  hidden_act = state\n",
        "  outputs = []\n",
        "  for X in input:\n",
        "    hidden = torch.matmul(X, W_xh) + torch.matmul(hidden_act, W_hh) + b_h\n",
        "    hidden_act = torch.tanh(hidden)\n",
        "    outputs.append(softmax(torch.matmul(hidden_act, W_hq) + b_q))\n",
        "\n",
        "  return (outputs, hidden_act)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFaCEwQoUROX"
      },
      "source": [
        "def init_rnn_hidden():\n",
        "  return torch.zeros((1, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ft-4JmEI3N"
      },
      "source": [
        "def cross_entropy(y_hat, y):\n",
        "  return -torch.mean(torch.sum(y * torch.log(y_hat)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ3O9VRSEGeA"
      },
      "source": [
        "def average_ce_loss(outputs, labels):\n",
        "    assert(len(outputs) == len(labels))\n",
        "    total_loss = 0.\n",
        "    for (output, label) in zip(outputs,labels):\n",
        "        total_loss = total_loss + cross_entropy(output, label)\n",
        "    return total_loss / len(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSSq9ZTrYtDa"
      },
      "source": [
        "def softmax(X):\n",
        "  lin = (X - torch.max(X).reshape((-1, 1)))\n",
        "  X_exp = torch.exp(lin)\n",
        "  partition = X_exp.sum(1, keepdim=True)\n",
        "  return X_exp / partition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot47fvWgaiOv"
      },
      "source": [
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    params = net\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkK0QlcteAR0"
      },
      "source": [
        "rnn = net\n",
        "criterion = average_ce_loss\n",
        "params = params\n",
        "lr = 0.005\n",
        "optimizer = torch.optim.SGD(params, lr)\n",
        "num_epochs = 75\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  state = init_rnn_hidden()\n",
        "  for i in range(num_batches):\n",
        "    input = train_iter[i]\n",
        "    train_labels = labels[i]\n",
        "    state = state.detach()\n",
        "    optimizer.zero_grad()\n",
        "    y_hat, state = rnn(input, state)\n",
        "    l = criterion(y_hat, train_labels)\n",
        "    l.sum().backward()\n",
        "    grad_clipping(params, 1)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    l_loss = criterion(y_hat, train_labels)\n",
        "    print(f'loss on epoch {epoch} was {l_loss}')\n",
        "    print(predict('on the other hand', 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6U-dOxFfuSQ"
      },
      "source": [
        "def predict(prefix, num_chars):\n",
        "  string = prefix\n",
        "  sample_state = init_rnn_hidden()\n",
        "  string_numerical = [character_dict[char] for char in prefix]\n",
        "  input = one_hot_data(string_numerical)\n",
        "  \n",
        "  for i in range(num_chars):\n",
        "    outputs, sample_state = rnn(input, sample_state)\n",
        "    choice = np.random.choice(50, p=fix_p(np.asarray(outputs[-1][0])))\n",
        "    string += uniq_tokens[choice]\n",
        "    input = one_hot_data([choice])\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYoKYIu4ctv"
      },
      "source": [
        "def fix_p(p):\n",
        "    if p.sum() != 1.0:\n",
        "        p = p*(1./p.sum())\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl_YhpPFQLje"
      },
      "source": [
        "my_generator = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llT268pxNsaE"
      },
      "source": [
        "prefix = 'my name is'\n",
        "string = prefix\n",
        "sample_state = init_rnn_hidden()\n",
        "string_numerical = [character_dict[char] for char in prefix]\n",
        "input = one_hot_data(string_numerical)\n",
        "\n",
        "for i in range(20):\n",
        "  with torch.no_grad():\n",
        "    outputs, sample_state = rnn(input, sample_state)\n",
        "    choice = np.random.choice(50, p=fix_p(np.asarray(outputs[-1][0])))\n",
        "    string += uniq_tokens[choice]\n",
        "    input = one_hot_data([choice])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhAOrbO2OVhM",
        "outputId": "0c1c029a-d6a6-4d5f-e1c3-1a511243d562"
      },
      "source": [
        "a = fix_p(outputs[-1][0].sum())\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}