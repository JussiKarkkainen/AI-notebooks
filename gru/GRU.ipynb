{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRUfromscratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZmp7fdQLFMd"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C95FwvwfLKr4"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtxYch1DOYhe"
      },
      "source": [
        "with open('ptb.train.txt') as f:\n",
        "  lines = f.readlines()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF3Ob-YROy0n"
      },
      "source": [
        "def get_tokens():\n",
        "  tokens = [list(line) for line in lines]\n",
        "  return tokens\n",
        "\n",
        "token = get_tokens()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYmnx4ZOPw7t",
        "outputId": "08febd09-f735-459a-fb56-b1f5bdb31b1f"
      },
      "source": [
        "def flatten(tokens):\n",
        "  return [items for i in tokens for items in i]\n",
        "\n",
        "tokens = flatten(token)\n",
        "print(len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5101618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoQmlEChQbeC",
        "outputId": "0a6a533e-7da1-4b81-82ab-ab1fa2bb5af8"
      },
      "source": [
        "def unique_char(tokens):\n",
        "  uniq_tokens = []\n",
        "  for i in tokens:\n",
        "    if i not in uniq_tokens:\n",
        "      uniq_tokens.append(i)\n",
        "  return uniq_tokens\n",
        "\n",
        "\n",
        "uniq_tokens = unique_char(tokens)\n",
        "print(len(uniq_tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXGNicGYRYSE"
      },
      "source": [
        "vocab = {}\n",
        "for e, char in enumerate(uniq_tokens):\n",
        "  vocab[char] = e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Plpn9F6SZER"
      },
      "source": [
        "wiki_numerical = [vocab[char] for char in tokens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l7vE2RkTZ8q"
      },
      "source": [
        "def one_hot_data(numerical_list, vocab_size=50):\n",
        "    result = torch.zeros((len(numerical_list), vocab_size))\n",
        "    for i, idx in enumerate(numerical_list):\n",
        "        result[i, idx] = 1.0\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdL1vINBTsQZ"
      },
      "source": [
        "def textify(embedding):\n",
        "    result = \"\"\n",
        "    indices = torch.argmax(embedding, axis=1)\n",
        "    for idx in indices:\n",
        "        result += uniq_tokens[int(idx)]\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj4vpZNtTuW3"
      },
      "source": [
        "seq_length = 64\n",
        "num_samples = (len(wiki_numerical) - 1) // seq_length\n",
        "dataset = one_hot_data(wiki_numerical[:num_samples * seq_length]).reshape(num_samples, seq_length, len(uniq_tokens))\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ja4H7j5XrjE"
      },
      "source": [
        "batch_size = 32\n",
        "num_batches = len(dataset) // batch_size\n",
        "train_iter = dataset[:num_batches * batch_size].reshape((batch_size, num_batches, seq_length, len(uniq_tokens)))\n",
        "train_iter = train_iter.swapaxes(0, 1)\n",
        "train_iter = train_iter.swapaxes(1, 2)\n",
        "train_iter.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAjsTfkSXzAK"
      },
      "source": [
        "labels = one_hot_data(wiki_numerical[1:num_samples * seq_length + 1]).reshape(batch_size, num_batches, seq_length, len(uniq_tokens))\n",
        "labels = labels.swapaxes(0, 1)\n",
        "labels = labels.swapaxes(1, 2)\n",
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy_D1ODCX3SZ"
      },
      "source": [
        "print(textify(train_iter[10, :, 3]))\n",
        "print(textify(labels[10, :, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIuJamY0vdgf"
      },
      "source": [
        "def init_hidden():\n",
        "  return torch.zeros((1, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdG8DK4MyiwV"
      },
      "source": [
        "W_xh = torch.normal(0, 0.01, (50, 256), requires_grad=True)\n",
        "W_hh = torch.normal(0, 0.01, (256, 256), requires_grad=True)\n",
        "b_h = torch.zeros((1, 256), requires_grad=True)\n",
        "\n",
        "W_xr = torch.normal(0, 0.01, (50, 256), requires_grad=True)\n",
        "W_hr = torch.normal(0, 0.01, (50, 256), requires_grad=True)\n",
        "b_r = torch.zeros(256, requires_grad=True)\n",
        "\n",
        "W_hr = torch.normal(0, 0.01, (256, 256), requires_grad=True)\n",
        "W_hz = torch.normal(0, 0.01, (256, 256), requires_grad=True)\n",
        "b_z = torch.zeros(256, requires_grad=True)\n",
        "\n",
        "W_hq = torch.normal(0, 0.01, (256, 50), requires_grad=True)\n",
        "b_q = torch.zeros(50, requires_grad=True)\n",
        "\n",
        "params = [W_xh, W_hh, b_h, W_xr, W_hr, b_r, W_hr, W_hz, b_z, W_hq, b_q]\n",
        "for param in params:\n",
        "  param.requires_grad_(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_bYhZVD0Zi8"
      },
      "source": [
        "def net(input, state):\n",
        "  W_xh, W_hh, b_h, W_xr, W_hr, b_r, W_hr, W_hz, b_z, W_hq, b_q = params\n",
        "  H_t = state\n",
        "  outputs = []\n",
        "  Sigmoid = torch.nn.Sigmoid()\n",
        "  Tanh = torch.nn.Tanh()\n",
        "  for x in input:\n",
        "    R_t = Sigmoid((x @ W_xr) + (H_t @ W_hr) + b_r)\n",
        "    Z_t = Sigmoid((x @ W_xr) + (H_t @ W_hz) + b_z)\n",
        "    cand_hid = Tanh(x @ W_xh + (R_t * H_t) @ W_hh + b_h)\n",
        "    H_t = Z_t * state + (1 - Z_t) * cand_hid\n",
        "    outputs.append(softmax(H_t @ W_hq + b_q))\n",
        "\n",
        "  return (outputs, H_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjFc5a9GjBgr"
      },
      "source": [
        "def crossentropy(y_hat, y):\n",
        "  return -torch.mean(torch.sum(y * torch.log(y_hat)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fICmWhOSjjcz"
      },
      "source": [
        "def average_ce_loss(outputs, labels):\n",
        "  assert(len(labels == len(outputs)))\n",
        "  total_loss = 0\n",
        "  for (outputs, labels) in zip(outputs, labels):\n",
        "    total_loss = total_loss + crossentropy(outputs, labels)\n",
        "  return total_loss / len(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjwaqZq2qNZL"
      },
      "source": [
        "def predict(prefix, num_chars):\n",
        "  string = prefix\n",
        "  sample_state = init_hidden()\n",
        "  string_numerical = [vocab[char] for char in prefix]\n",
        "  input = one_hot_data(string_numerical)\n",
        "  \n",
        "  for i in range(num_chars):\n",
        "    outputs, sample_state = rnn(input, sample_state)\n",
        "    choice = np.random.choice(50, p=fix_p(np.asarray(outputs[-1][0])))\n",
        "    string += uniq_tokens[choice]\n",
        "    input = one_hot_data([choice])\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO2zi1UzkekY"
      },
      "source": [
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    params = net\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NJJIpgCkjK8"
      },
      "source": [
        "def softmax(X):\n",
        "  lin = (X - torch.max(X).reshape((-1, 1)))\n",
        "  X_exp = torch.exp(lin)\n",
        "  partition = X_exp.sum(1, keepdim=True)\n",
        "  return X_exp / partition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKlTm_oei5hO"
      },
      "source": [
        "num_epochs = 500\n",
        "criterion = average_ce_loss\n",
        "params = params\n",
        "lr = 0.01\n",
        "optimizer = torch.optim.SGD(params, lr)\n",
        "rnn = net\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  state = init_hidden()\n",
        "  for i in range(num_batches):\n",
        "    input = train_iter[i]\n",
        "    train_labels = labels[i]\n",
        "    state = state.detach()\n",
        "    optimizer.zero_grad()\n",
        "    y_hat, state = rnn(input, state)\n",
        "    l = criterion(y_hat, train_labels)\n",
        "    l.sum().backward()\n",
        "    grad_clipping(params, 1)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    l_loss = criterion(y_hat, train_labels)\n",
        "    print(f'loss on epoch {epoch} was {l_loss}')\n",
        "    print(predict('on the other hand', 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsP6sFn8mLTG"
      },
      "source": [
        "def fix_p(p):\n",
        "    if p.sum() != 1.0:\n",
        "        p = p*(1./p.sum())\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-37xtHNmaUz"
      },
      "source": [
        "my_generator = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}